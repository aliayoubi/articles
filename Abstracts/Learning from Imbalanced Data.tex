\documentclass{article}
\usepackage{graphicx}
\usepackage{xepersian}
\usepackage{geometry}
\settextfont[Scale=1.2]{XB Zar}

% section numbering
\setcounter{secnumdepth}{3}
\renewcommand{\thesection}{\arabic{section}}
\renewcommand{\thesubsection}{\thesection.\arabic{subsection}}
\renewcommand{\thesubsubsection}{\thesection.\arabic{subsection}.\arabic{subsubsection}}

\title{ 
\begin{normalsize} به نام خدا \end{normalsize}
\\[7cm]
چکیده مقاله یادگیری از روی دادگان نامتوازن
\\[3cm]
}
\author{علیرضا نوریان
\\
\\ \small دانشگاه علم و صنعت ایران
\\ \small noorian@comp.iust.ac.ir
}

\begin{document}
\maketitle

\section{مقدمه}
رشد حجم داده‌های موجود در زمینه‌های متخلف، موجب تمرکز فعالیتهای پژوهشی بر روی آنها شده است. بیشتر الگوریتم‌های تهیه شده برای کاوش متن، انتظار ورودی گرفتن داده‌هایی با توزیع استاندارد دارند. به همین دلیل در برخورد با داده‌های نامتوازن، به درستی عمل نمی‌کنند. این مساله، وقتی بیشتر مورد توجه قرار می‌گیرد که متوجه شیوع گسترده توزیع نامتوازن در داده‌های دنیای واقع هستیم.
\section{شرح مساله}
منظور از دادگان نامتوازن، توزیع کلاسها به صورت نامساوی و با اختلاف بسیار  زیاد مثل صد یا هزار براربر است. که بی‌تردید موجب به وجود آمدن تمایل بیش از حد در قضاوت می‌شود. بعضی از انواع دادگان مثل دادگان مربوط به یک بیماری نادر و یا نفوذ به یک سایت، به صورت ذاتی، نامتوازن هستند. در مقابل عواملی خارجی، مثل نقص در اندازه‌گیری‌ها و یا محدودیت‌های حجمی و یا زمانی مربوط به ذخیره‌سازی داده‌ها، موجب از بین رفتن توازن در دادگان می‌شوند.
عدم توازن در دادگان می‌تواند به صورت نسبی وجود داشته باشد. برای نمونه اگر از میان ۱۰۰۰۰ نمونه، فراوانی یکی از کلاسها ۱۰۰ برابر دیگری باشد، باید تقریبا ۱۰۰۰ نمونه از کلاس دیگر وجود دارد. در این شرایط اگرچه یادگیری کمی دچار خطا می‌شود، اما بیشتر عوامل مربوط به پیچیدگی مساله موثر هستند. در مقابل وقتی تعداد داده‌ها کم و یا تعداد ویژگی‌ها بسیار زیاد است، یادگیری شدیدا تحت تاثیر این مشکل قرار می‌گیرد.
\section{بهترین روشهای یادگیری نامتوازن}

\subsection{روشهای نمونه‌برداری}
دلیل اصلی استفاده از نمونه‌برداری در دادگان نامتوازن، برقراری توازن میان آنها است. البته بدون نمونه‌برداری هم یادگیری ممکن است ولی با این روش موجب بالا رفتن صحت در آزمایش‌ها می‌شود.

\subsubsection{نمونه‌برداری اتفاقی}
ساده‌ترین روش برای برقراری توازن، تکرار نمونه‌های نادر و یا حذف نمونه‌های فراوان به صورت اتفاقی و به اندازه‌ی لازم است. حذف نمونه‌های فراوان موجب حذف بعضی از شواهد تشخیص می‌شود و در مقابل تکرار نمونه‌های نادر، معیارهای تشخص را مختص همان نمونه‌ها می‌کند.

\subsubsection{حذف نمونه‌ها}
برای پرهیز از مشکلات ذکر شده، باید نمونه‌برداری را هوشمندانه‌تر انجام داد. الگوریتم EasyEnsemble با همین هدف، به طور اتفاقی مجموعه‌هایی را از داده‌های اکثریت انتخاب کرده و برای تفکیک هر کدام از آنها و مجموعه داده‌های اقلیت، یک ابزار رده‌بندی\LTRfootnote{Classifier} تولید می‌کند. BalanceCascade عنوان الگوریتم دیگری برای انجام همین کار است. این الگوریتم در هر نوبت اجرا، مجموعه‌ای به تعداد داده‌های اقلیت از داده‌های اکثریت جدا کرده و ابزاری برای رده‌بندی آنها ایجاد می‌کند. سپس با استفاده از همین ابزار مجموعه‌ی حاصل از ترکیب داده‌های جدا شده و داده‌های اقلیت را رده‌بندی می‌کند. داده‌هایی که در این بخش در رده‌ی اکثریت قرار گیرند، توسط ابزار رده‌بندی شناخته شده‌اند، پس آنها را از مجموعه‌ی داده‌های اصلی حذف می‌کند. ادامه دادن این رویه موجب تولید یک ابزار مناسب برای رده‌بندی می‌شود.
همچنین روشهایی برای کاهش آگاهانه‌ی داده‌های اکثریت با استفاده از الگوریتم KNN پیشنهاد شده است. برای نمونه در یکی از این روشها، نمونه‌هایی از داده‌های اکثریت را حذف می‌کنیم که فاصله‌ی آنها از دورترین نمونه‌های اقلیت، کوتاهتر باشد و به این ترتیب مرز میان دو گروه واضح‌تر می‌شود.

\subsubsection{تولید نمونه}
افزودن نمونه به مجموعه‌ی اقلیت نیز با روشهای مختلفی انجام می‌شود. الگوریتم SMOTE که از انواع موفق در این روش است، سعی می‌کند نمونه‌هایی را شبیه به نمونه‌های موجود تولید کند. برای این کار، دو نمونه نزدیک به هم را به طور اتفاقی انتخاب کرده و نمونه‌ای بین آنها (با ترکیب ویژگی‌های آنها) ایجاد می‌کند.
شکل تکامل یافته‌تری از این فرایند، به محدوده‌های نیازمند تولد نمونه توجه می‌کند. در این روش نمونه‌ی جدید در میان نمونه‌هایی از اقلیت ایجاد می‌شوند که در مجاورت تعداد قابل توجهی نمونه‌ی اکثریت قرار گرفته‌اند. به این ترتیب نمونه‌هایی که بیشتر احتمال خطا در مورد آنها وجود دارد، تقویت می‌شوند. بعد از تولید نمونه با حذف نمونه‌های مرزی داده‌های اکثریت و اقلیت، مجموعه‌ی داده‌ها بسیار تمیزتر شده و ابزار رده‌بندی در این حالت راحت‌تر قضاوت می‌کند.
روش دیگر برای تولید نمونه، استفاده از خوشه‌بندی است. در این روش ابتدا داده‌ها خوشه‌بندی می‌شوند و مرکز هر خوشه مشخص می‌شود. بعد از این مرحله باید خوشه‌های اقلیت به اندازه‌ی خوشه‌های اکثریت پر شوند. با توجه به مشخص بودن مرز میان خوشه‌ها، تولید نمونه اتفاقی در محدوده‌ی هر خوشه بسیار آسان است.
تولید نمونه از حذف نمونه پیچیده‌تر است و نیاز به محاسبه‌ی بیشتری هم دارد. به همین دلیل روشهایی ترکیبی ایجاد شده‌اند که هم از ایده‌ی انتخاب‌های متعدد از مجموعه‌ی اکثریت استفاده می‌کنند و هم با تکرار داده‌های اقلیت، سعی می‌کنند تشخیص آنها را آسانتر کنند.

\subsection{روشهای هزینه محور}
روشهای نمونه‌برداری سعی در برقراری توازن میان نمونه‌ها هستند، در حالی که روشهای هزینه محور، با توجه به هزینه‌ی رده‌بندی اشتباه، برای کاهش هزینه تلاش می‌کنند. در واقع هرچه زیان یک اشتباه بیشتر باشد، امکان وقوع آن باید کم شود.

\subsubsection{وزن‌دهی داده‌ها}
این روش منطقی مشابه نمونه‌برداری دارد. در واقع در اینجا نیز قرار است، مجموعه‌ای از داده‌ها انتخاب شوند و ابزار رده‌بندی از روی مجموعه‌ای انتخاب شده، به روز رسانی شود. انتخاب این مجموعه به صورت اتفاقی از میان داده‌ها صورت می‌گیرد. البته احتمال انتخاب شدن داده‌ها با هم برابر نیست. بلکه داده‌هایی که بروز خطای رده‌بندی در مورد آنها هزینه‌ی بیشتری دارد، شانس بیشتری برای حضور در این مجموعه را دارند. این رویه بارها تکرار می‌شود و در نهایت یک ابزار رده‌بندی با حداقل هزینه‌ی انجام این کار، تولید می‌شود.
\subsubsection{درختهای تصمیم هزینه محور}
هزینه‌ی انجام اشتباهات می‌تواند در مراحل مختلف ایجاد درخت تصمیم استفاده شود. مراحل مورد نظر همان انتخاب ویژگی، انتخاب مرز تصمیم و هرس درخت هستند. فرایند هرس برای داده‌های نامتوازن، تمایل بیشتری به حذف برگهای مربوط به کلاس اقلیت دارد و با این کار احتمال انتخاب شدن آنها را افزایش می‌دهد. همچنین برای انتخاب ویژگی‌ها بجای استفاده از معیار آنتروپی و یا جینی، از معیاری استفاده می‌کنیم که هزینه‌ی تصمیم‌های اشتباه را نیز در نظر بگیرد.
بخشهای مختلف فرایند اصلاح یک شبکه عصبی نیز قابلیت در نظر گرفتن هزینه‌ی انتخابها را دارند. برای نمونه این معیار می‌تواند روی خروجی‌های شبکه، تابع کاهش خطا و ... اعمال شود. همچنین ابزارهای رده‌بندی دیگر مثل Bayesian و یا SVM نیز قابلیت اعمال معیار هزینه را دارند.

\section{معیارهای ارزیابی}

\subsection{معیارهای ارزیابی منفرد}
صحت از معیارهای بسیار مرسوم برای ارزیابی یک روش رده‌بندی است و خصوصا شکل کامل‌تر آن به عنوان ماتریس اشتباهات\LTRfootnote{Confusion Matrix} تا حد زیادی قضاوت در مورد کیفیت را آسان می‌کند. معیار صحت به صورت نسبی محاسبه می‌شود، پس نامتوازن بودن دادگان به شدت آن را تحت تاثیر قرار می‌دهد.
برای جبران نقص‌های مربوط به صحت، معیارهای دیگری نیز تعریف شده‌اند. دقت معیاری است که اعتماد ما را به پاسخی که مثبت تشخیص داده شده، مشخص می‌کند. معیار recall برای سنجش میزان کامل بودن پاسخ‌ها تعریف شده است. با این معیار می‌خواهیم بفهمیم که چه بخشی از پاسخ‌های مثبت درست تشخیص داده شده‌اند. دقت به نحوه توزیع دادگان وابسته است، اما معیار recall این طور نیست. البته recall مشخص نمی‌کند که چه بخشی از داده‌ها اشتباها مثبت تشخیص داده شده‌اند. معیار F-Measure از ترکیب این دو معیار به دست می‌آید و بهتر از معیار صحت، ابزار رده‌بندی را ارزیابی می‌کند. به طور مشابه، معیار G-Mean از ترکیب صحت داده‌های مثبت و منفی بدست می‌آید. اگرچه این معیارهای ترکیبی گویاتر از معیارهای ساده هستند، اما باز هم خواسته‌ی ما را بر آورده نمی‌کنند. در واقع هدف یافتن معیاری برای مقایسه میان روش‌های مختلف روی دادگانی با توزیع‌های مختلف است.

\subsection{معیارهای ارزیابی نموداری}
نمودار ROC برای نمایش میزان تشخیص‌های مثبت صحیح به تشخیص‌های مثبت غلط ایجاد شده است. در این نمودار می‌توان اجرای یک ابزار رده‌بندی را روی دادگانی با توزیع‌های مختلف نمایش داد. نمایش هر کدام از این اجراها به صورت یک نقطه در نمودرا انجام می‌شود و افزایش تعداد اجراها موجب نمایش منحنی مربوط به آن ابزار می‌شود. مساحت زیر این منحنی کاملا مشخص می‌کند که این ابزار رده‌بندی چقدر در مقابل توزیع‌های مختلف کلاس‌ها در دادگان مقاوم است و با این روش به راحتی می‌توان ابزارهای مختلف را مقایسه کرد. نمودار PR نیز برای حل مساله مقایسه میان ابزارها ایجاد شده و در آن میزان دقت بر حسب recall نمایش داده می‌شود. وقتی که دادگان به شدت نامتوازن باشند، خروجی‌های نمودار PR واقع‌بینانه‌تر از نمودار ROC است. یکی دیگر از نقص‌های نمودار ROC در نظر نگرفتن هزینه‌ی مربوط به اشتباه است و برای نمایش هزینه باید از نمودارهایی مختص همین کار استفاده کنیم.

\end{document}
